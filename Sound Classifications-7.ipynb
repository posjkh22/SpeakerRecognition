{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_class:  5\n",
      "item_num in class 1 :  3\n",
      "item_num in class 2 :  2\n",
      "item_num in class 3 :  1\n",
      "item_num in class 4 :  2\n",
      "item_num in class 5 :  2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_path = './data4/'\n",
    "\n",
    "nb_classes = len(os.listdir(data_path))\n",
    "\n",
    "print(\"nb_class: \", nb_classes)\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    print(\"item_num in class\", sub_path+1, \": \" , len(item_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0 in 1 done!\n",
      "load 1 in 1 done!\n",
      "load 2 in 1 done!\n",
      "load 0 in 2 done!\n",
      "load 1 in 2 done!\n",
      "load 0 in 3 done!\n",
      "load 0 in 4 done!\n",
      "load 1 in 4 done!\n",
      "load 0 in 5 done!\n",
      "load 1 in 5 done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = [None] * nb_classes\n",
    "sr = [None] * nb_classes\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    y[sub_path] = [None] * len(item_num)\n",
    "    sr[sub_path] = [None] * len(item_num)\n",
    "\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        y[sub_path][i], sr[sub_path][i] = librosa.load(data_path + str(sub_path+1) + '/' + str(i) + '.wav')\n",
    "        print(\"load\", i,\"in\", sub_path+1, \"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0 in 1 : (15736544,)\n",
      "Shape 1 in 1 : (19245216,)\n",
      "Shape 2 in 1 : (19707744,)\n",
      "Shape 0 in 2 : (8401504,)\n",
      "Shape 1 in 2 : (44215840,)\n",
      "Shape 0 in 3 : (37069728,)\n",
      "Shape 0 in 4 : (23162784,)\n",
      "Shape 1 in 4 : (43805344,)\n",
      "Shape 0 in 5 : (10233824,)\n",
      "Shape 1 in 5 : (38102304,)\n"
     ]
    }
   ],
   "source": [
    "# audio data verification\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        print(\"Shape\", i,\"in\", sub_path+1, \":\", y[sub_path][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22050, 22050, 22050], [22050, 22050], [22050], [22050, 22050], [22050, 22050]]\n",
      "22050\n"
     ]
    }
   ],
   "source": [
    "# sampling rate verification\n",
    "\n",
    "print(sr)\n",
    "print(sr[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0 in 1 : (15736544,)\n",
      "Shape 1 in 1 : (19245216,)\n",
      "Shape 2 in 1 : (19707744,)\n",
      "Shape 0 in 2 : (8401504,)\n",
      "Shape 1 in 2 : (44215840,)\n",
      "Shape 0 in 3 : (37069728,)\n",
      "Shape 0 in 4 : (23162784,)\n",
      "Shape 1 in 4 : (43805344,)\n",
      "Shape 0 in 5 : (10233824,)\n",
      "Shape 1 in 5 : (38102304,)\n"
     ]
    }
   ],
   "source": [
    "# audio data verification\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        print(\"Shape\", i,\"in\", sub_path+1, \":\", y[sub_path][i].shape)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked Audio raw data\n",
      "(54689504,)\n",
      "(52617344,)\n",
      "(37069728,)\n",
      "(66968128,)\n",
      "(48336128,)\n"
     ]
    }
   ],
   "source": [
    "# audio_data_stack\n",
    "\n",
    "\n",
    "audio_data = [None] * nb_classes\n",
    "\n",
    "for sub_path in range (0, nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        \n",
    "        if len(item_num) == 1:\n",
    "            audio_data[sub_path] = y[sub_path][0] \n",
    "\n",
    "        else:\n",
    "\n",
    "            if i == 0:\n",
    "                audio_data[sub_path] = np.hstack([y[sub_path][i], y[sub_path][i+1]]) \n",
    "\n",
    "            elif i == 1:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                audio_data[sub_path] = np.hstack([audio_data[sub_path], y[sub_path][i]]) \n",
    "\n",
    "print(\"\\nStacked Audio raw data\")    \n",
    "for sub_path in range (0, nb_classes):        \n",
    "    print(audio_data[sub_path].shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked Audio raw data\n",
      "(54689504,)\n",
      "(52617344,)\n",
      "(37069728,)\n",
      "(66968128,)\n",
      "(48336128,)\n",
      "37069728\n",
      "6178288\n",
      "\n",
      "Resized Audio raw data\n",
      "(6136400,)\n",
      "(6136400,)\n",
      "(6136400,)\n",
      "(6136400,)\n",
      "(6136400,)\n",
      "\n",
      "Reshaped Audio raw data\n",
      "(29, 211600)\n",
      "(29, 211600)\n",
      "(29, 211600)\n",
      "(29, 211600)\n",
      "(29, 211600)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStacked Audio raw data\")    \n",
    "for sub_path in range (0, nb_classes):        \n",
    "    print(audio_data[sub_path].shape)\n",
    "\n",
    "min = 9999999999\n",
    "\n",
    "for i in range (0, 5):\n",
    "    if min > audio_data[i].shape[0]:\n",
    "        min = audio_data[i].shape[0] \n",
    "\n",
    "print(min)\n",
    "\n",
    "input_data_size = 460\n",
    "\n",
    "min = int(min/6)\n",
    "\n",
    "print(min)\n",
    "\n",
    "\n",
    "min = min - min %(input_data_size * input_data_size)\n",
    "    \n",
    "\n",
    "print(\"\\nResized Audio raw data\")    \n",
    "for i in range (0, 5):\n",
    "    audio_data[i] = audio_data[i][0:min]\n",
    "    print(audio_data[i].shape)\n",
    "\n",
    "\n",
    "#print(\"\\nReshaped Audio raw data\")    \n",
    "#for i in range (0, 5):\n",
    "#    audio_data[i] = audio_data[i].reshape(-1, 1)\n",
    "#    print(audio_data[i].shape)      \n",
    "    \n",
    "print(\"\\nReshaped Audio raw data\")    \n",
    "for i in range (0, 5):\n",
    "    audio_data[i] = audio_data[i].reshape(-1, input_data_size * input_data_size)\n",
    "    print(audio_data[i].shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 1)\n",
      "(29, 1)\n",
      "(29, 1)\n",
      "(29, 1)\n",
      "(29, 1)\n",
      "(29, 211601)\n",
      "(29, 211601)\n",
      "(29, 211601)\n",
      "(29, 211601)\n",
      "(29, 211601)\n"
     ]
    }
   ],
   "source": [
    "# labeling\n",
    "y = [None] * nb_classes\n",
    "\n",
    "    \n",
    "for i in range (0, nb_classes):\n",
    "    y[i] = np.ones((int(min/(input_data_size * input_data_size)), 1), dtype='int') * (i+1) -1\n",
    "    print(y[i].shape)\n",
    "\n",
    "\n",
    "for i in range (0, nb_classes):\n",
    "    audio_data[i] = np.hstack([audio_data[i], y[i]])\n",
    "    print(audio_data[i].shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 211601)\n",
      "[-0.0076983  -0.02352953 -0.02818573 ...  0.0056458   0.01052093\n",
      "  0.        ]\n",
      "(145, 211601)\n"
     ]
    }
   ],
   "source": [
    "# input data shuffling\n",
    "\n",
    "\n",
    "audio_data_append = []\n",
    "\n",
    "for i in range (0, nb_classes):\n",
    "    \n",
    "    if i == 0:\n",
    "        audio_data_append = np.vstack([audio_data[i], audio_data[i+1]])\n",
    "    \n",
    "    elif i == 1:\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        audio_data_append = np.vstack([audio_data_append, audio_data[i]])\n",
    "\n",
    "\n",
    "print(audio_data_append.shape)\n",
    "\n",
    "print(audio_data_append[20])\n",
    "\n",
    "\n",
    "np.random.shuffle(audio_data_append)\n",
    "\n",
    "audio_data_shuffle = audio_data_append\n",
    "print(audio_data_append.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL IN/OUTPUT SHAPE\n",
      "Input X:  (145, 211600)\n",
      "Output Y_one_hot:  (145, 5)\n",
      "\n",
      "FINAL IN/OUTPUT DATA\n",
      "[[ 0.03953372  0.05508901  0.05231933 ...  0.04687595  0.05402173\n",
      "   0.05538728]\n",
      " [-0.00401856 -0.00358174 -0.00222191 ... -0.02728347 -0.03176821\n",
      "  -0.03719559]\n",
      " [-0.14958137 -0.18193342 -0.16024043 ... -0.29296631 -0.21872884\n",
      "  -0.18979269]\n",
      " ...\n",
      " [-0.50348908 -0.5323875  -0.56361306 ... -0.21638727 -0.23412044\n",
      "  -0.26359209]\n",
      " [-0.04003545  0.07358342  0.00224287 ... -0.04092641 -0.04462469\n",
      "  -0.04518472]\n",
      " [ 0.00128514  0.00153497  0.00129209 ... -0.18931681 -0.20304005\n",
      "  -0.17296927]]\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# labeled value one-hot encoding\n",
    "\n",
    "audio_data_shuffle_T = audio_data_shuffle.transpose()\n",
    "\n",
    "x_data_t = audio_data_shuffle_T[:-1]\n",
    "y_data_t = audio_data_shuffle_T[-1:]\n",
    "x_data = x_data_t.transpose()\n",
    "y_data_t = y_data_t.flatten()\n",
    "\n",
    "\n",
    "\n",
    "y_data_one_hot = tf.one_hot(y_data_t, nb_classes, dtype=tf.float32)\n",
    "\n",
    "tf.InteractiveSession().as_default()\n",
    "tf.tables_initializer().run()\n",
    "\n",
    "y_data_one_hot = y_data_one_hot.eval()\n",
    "\n",
    "\n",
    "print(\"FINAL IN/OUTPUT SHAPE\")\n",
    "print(\"Input X: \", x_data.shape)\n",
    "print(\"Output Y_one_hot: \", y_data_one_hot.shape)\n",
    "\n",
    "print(\"\\nFINAL IN/OUTPUT DATA\")\n",
    "print(x_data)\n",
    "print(y_data_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Shape_1:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# CNN (3 Conv + MP) + 1 FCN + 1 Output\n",
    "\n",
    "training_number = 9000\n",
    "learning_rate = 0.01\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"sound_classifications-7-3\") as scope:\n",
    "    tf.variable_scope(scope, reuse=True)\n",
    "    \n",
    "    # Input Audio data of shape 460 * 460 = 211,600\n",
    "    X = tf.placeholder(tf.float32, [None, 211600])\n",
    "    X_reshaped = tf.reshape(X, [-1, 460, 460, 1])\n",
    "    # 0 - 9 digits recognition = 10 classes\n",
    "    Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "\n",
    "    # Conv 1\n",
    "    W1 = tf.Variable(tf.random_normal([100, 100, 1, 32], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_reshaped, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "    \n",
    "    # X ImgIn shape=(?, 460, 460, 1)\n",
    "    #    Conv      ->(?, 460, 460, 32)\n",
    "    #    Pool      ->(?, 230, 230, 32)\n",
    "    \n",
    "    \n",
    "    # Conv 2\n",
    "    W2 = tf.Variable(tf.random_normal([100, 100, 32, 64], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "    \n",
    "    # L1 ImgIn shape=(?, 230, 230, 32)\n",
    "    #    Conv      ->(?, 230, 230, 64)\n",
    "    #    Pool      ->(?, 115, 115, 64)\n",
    "    \n",
    "    \n",
    "    # Conv 3\n",
    "    W3 = tf.Variable(tf.random_normal([50, 50, 64, 128], stddev=0.01))\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "    L3_flat = tf.reshape(L3, [-1, 128 * 58 * 58])\n",
    "    \n",
    "    # L2 ImgIn shape=(?, 115, 115, 64)\n",
    "    #    Conv      ->(?, 115, 115, 128)\n",
    "    #    Pool      ->(?, 58, 58, 128) \n",
    "    \n",
    "    # FC\n",
    "    W4 = tf.get_variable(\"W4\", shape=[128 * 58 * 58, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([625]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "    \n",
    "    # Output\n",
    "    W5 = tf.get_variable(\"W5\", shape=[625, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "print(tf.shape(L1))\n",
    "print(tf.shape(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-004f43bf99a3>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-17-004f43bf99a3>:6: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "is_correct = tf.equal(tf.arg_max(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10 0\n",
      "20 0\n",
      "30 0\n",
      "40 0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "cost_history = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(int(training_number/batch_size)):\n",
    "        batch_count = int(x_data.shape[0]/batch_size)\n",
    "        \n",
    "        curr_cost = 0\n",
    "        \n",
    "        for i in range(batch_count):\n",
    "    \n",
    "            batch_xs, batch_ys = x_data[i* batch_size: i*batch_size+batch_size], y_data_one_hot[i*batch_size:i*batch_size+batch_size]\n",
    "        \n",
    "            sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "\n",
    "            curr_cost = sess.run(cost, feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "            \n",
    "            \n",
    "        if epoch % 10 == 0:    \n",
    "            print(epoch, curr_cost)\n",
    "            cost_history.append(curr_cost)\n",
    "                                \n",
    "                                \n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: x_data, Y: y_data_one_hot, keep_prob: 1})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
