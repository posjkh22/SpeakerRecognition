{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# label \n",
    "# 01: risabae https://www.youtube.com/watch?v=xsBKNABqi5E\n",
    "# 02: ssin https://www.youtube.com/watch?v=73fUeFCbeX0\n",
    "# 03: seon story  https://www.youtube.com/watch?v=ObD9i534dWo\n",
    "# 04: gond dea sang byun https://www.youtube.com/watch?v=bkOmOWHqf5Y\n",
    "# 05: carrieandtoys https://www.youtube.com/watch?v=JpiJoYXquh4\n",
    "# 06: big library https://www.youtube.com/watch?v=uGv_X4C18NI\n",
    "# 07: yangthing https://www.youtube.com/watch?v=OpdvcUAYp9A\n",
    "# 08: bokyum https://www.youtube.com/watch?v=4nkCoELM4zU\n",
    "# 09: heopop https://www.youtube.com/watch?v=-ajBifuuglg\n",
    "# 10: cook tv https://www.youtube.com/watch?v=iAvEcepENUU\n",
    "#             https://www.youtube.com/watch?v=AUt3bZvhs_Q\n",
    "# 11: raon lee https://www.youtube.com/watch?v=VFO8OGyuJVo\n",
    "#              https://www.youtube.com/watch?v=NCGGxr1GPN0\n",
    "# 12: benz https://www.youtube.com/watch?v=N9ykrWXZyZU\n",
    "# 13: doty tv https://www.youtube.com/watch?v=FyvTigUETZ0\n",
    "# 14: maangchi https://www.youtube.com/watch?v=VO3EiWBH15Y\n",
    "# 15: british man https://www.youtube.com/watch?v=l-7U1Nn7zPI\n",
    "# 16: bj thung ge thung https://www.youtube.com/watch?v=7xqbLbRIYsw\n",
    "# 17: pony makeup https://www.youtube.com/watch?v=xnA-HnNyXXs\n",
    "# 18: crocodile https://www.youtube.com/watch?v=7HCBjDIv01M\n",
    "# 19: jflamusic https://www.youtube.com/watch?v=QKEKYm3mIFA\n",
    "#               https://www.youtube.com/watch?v=qu9V8jhWeYA\n",
    "#               https://www.youtube.com/watch?v=bSPCZSqYsDc\n",
    "# 20: jamthle tv https://www.youtube.com/watch?v=la4e2i4TWiw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_class:  20\n",
      "item_num in class 1 :  1\n",
      "item_num in class 2 :  1\n",
      "item_num in class 3 :  1\n",
      "item_num in class 4 :  1\n",
      "item_num in class 5 :  1\n",
      "item_num in class 6 :  1\n",
      "item_num in class 7 :  1\n",
      "item_num in class 8 :  1\n",
      "item_num in class 9 :  1\n",
      "item_num in class 10 :  2\n",
      "item_num in class 11 :  2\n",
      "item_num in class 12 :  1\n",
      "item_num in class 13 :  1\n",
      "item_num in class 14 :  1\n",
      "item_num in class 15 :  1\n",
      "item_num in class 16 :  1\n",
      "item_num in class 17 :  1\n",
      "item_num in class 18 :  1\n",
      "item_num in class 19 :  3\n",
      "item_num in class 20 :  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = './data5/'\n",
    "\n",
    "nb_classes = len(os.listdir(data_path))\n",
    "\n",
    "print(\"nb_class: \", nb_classes)\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    print(\"item_num in class\", sub_path+1, \": \" , len(item_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0 in 1 done!\n",
      "load 0 in 2 done!\n",
      "load 0 in 3 done!\n",
      "load 0 in 4 done!\n",
      "load 0 in 5 done!\n",
      "load 0 in 6 done!\n",
      "load 0 in 7 done!\n",
      "load 0 in 8 done!\n",
      "load 0 in 9 done!\n",
      "load 0 in 10 done!\n",
      "load 1 in 10 done!\n",
      "load 0 in 11 done!\n",
      "load 1 in 11 done!\n",
      "load 0 in 12 done!\n",
      "load 0 in 13 done!\n",
      "load 0 in 14 done!\n",
      "load 0 in 15 done!\n",
      "load 0 in 16 done!\n",
      "load 0 in 17 done!\n",
      "load 0 in 18 done!\n",
      "load 0 in 19 done!\n",
      "load 1 in 19 done!\n",
      "load 2 in 19 done!\n",
      "load 0 in 20 done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_y = [None] * nb_classes\n",
    "_sr = [None] * nb_classes\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    _y[sub_path] = [None] * len(item_num)\n",
    "    _sr[sub_path] = [None] * len(item_num)\n",
    "\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        _y[sub_path][i], _sr[sub_path][i] = librosa.load(data_path + str(sub_path+1) + '/' + str(i) + '.wav')\n",
    "        print(\"load\", i,\"in\", sub_path+1, \"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = _y\n",
    "sr = _sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0 in 1 : (22032544,)\n",
      "Shape 0 in 2 : (23131808,)\n",
      "Shape 0 in 3 : (10374368,)\n",
      "Shape 0 in 4 : (13448160,)\n",
      "Shape 0 in 5 : (16338976,)\n",
      "Shape 0 in 6 : (24051424,)\n",
      "Shape 0 in 7 : (23794944,)\n",
      "Shape 0 in 8 : (15737600,)\n",
      "Shape 0 in 9 : (18264160,)\n",
      "Shape 0 in 10 : (6625952,)\n",
      "Shape 1 in 10 : (7333984,)\n",
      "Shape 0 in 11 : (7309792,)\n",
      "Shape 1 in 11 : (5510816,)\n",
      "Shape 0 in 12 : (25242336,)\n",
      "Shape 0 in 13 : (28452384,)\n",
      "Shape 0 in 14 : (25071328,)\n",
      "Shape 0 in 15 : (12323840,)\n",
      "Shape 0 in 16 : (27639552,)\n",
      "Shape 0 in 17 : (16686944,)\n",
      "Shape 0 in 18 : (21218464,)\n",
      "Shape 0 in 19 : (4375712,)\n",
      "Shape 1 in 19 : (3255776,)\n",
      "Shape 2 in 19 : (3396128,)\n",
      "Shape 0 in 20 : (19783072,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# audio data verification\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        print(\"Shape\", i,\"in\", sub_path+1, \":\", y[sub_path][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22050], [22050], [22050], [22050], [22050], [22050], [22050], [22050], [22050], [22050, 22050], [22050, 22050], [22050], [22050], [22050], [22050], [22050], [22050], [22050], [22050, 22050, 22050], [22050]]\n",
      "22050\n"
     ]
    }
   ],
   "source": [
    "# sampling rate verification\n",
    "\n",
    "print(sr)\n",
    "print(sr[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0 in 1 : (22032544,)\n",
      "Shape 0 in 2 : (23131808,)\n",
      "Shape 0 in 3 : (10374368,)\n",
      "Shape 0 in 4 : (13448160,)\n",
      "Shape 0 in 5 : (16338976,)\n",
      "Shape 0 in 6 : (24051424,)\n",
      "Shape 0 in 7 : (23794944,)\n",
      "Shape 0 in 8 : (15737600,)\n",
      "Shape 0 in 9 : (18264160,)\n",
      "Shape 0 in 10 : (6625952,)\n",
      "Shape 1 in 10 : (7333984,)\n",
      "Shape 0 in 11 : (7309792,)\n",
      "Shape 1 in 11 : (5510816,)\n",
      "Shape 0 in 12 : (25242336,)\n",
      "Shape 0 in 13 : (28452384,)\n",
      "Shape 0 in 14 : (25071328,)\n",
      "Shape 0 in 15 : (12323840,)\n",
      "Shape 0 in 16 : (27639552,)\n",
      "Shape 0 in 17 : (16686944,)\n",
      "Shape 0 in 18 : (21218464,)\n",
      "Shape 0 in 19 : (4375712,)\n",
      "Shape 1 in 19 : (3255776,)\n",
      "Shape 2 in 19 : (3396128,)\n",
      "Shape 0 in 20 : (19783072,)\n"
     ]
    }
   ],
   "source": [
    "# audio data verification\n",
    "\n",
    "for sub_path in range(nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        print(\"Shape\", i,\"in\", sub_path+1, \":\", y[sub_path][i].shape)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked Audio raw data\n",
      "(22032544,)\n",
      "(23131808,)\n",
      "(10374368,)\n",
      "(13448160,)\n",
      "(16338976,)\n",
      "(24051424,)\n",
      "(23794944,)\n",
      "(15737600,)\n",
      "(18264160,)\n",
      "(13959936,)\n",
      "(12820608,)\n",
      "(25242336,)\n",
      "(28452384,)\n",
      "(25071328,)\n",
      "(12323840,)\n",
      "(27639552,)\n",
      "(16686944,)\n",
      "(21218464,)\n",
      "(11027616,)\n",
      "(19783072,)\n"
     ]
    }
   ],
   "source": [
    "# audio_data_stack\n",
    "\n",
    "\n",
    "audio_data = [None] * nb_classes\n",
    "\n",
    "for sub_path in range (0, nb_classes):\n",
    "    item_num = os.listdir(data_path+str(sub_path+1))\n",
    "    \n",
    "    for i in range(len(item_num)):\n",
    "        \n",
    "        if len(item_num) == 1:\n",
    "            audio_data[sub_path] = y[sub_path][0] \n",
    "\n",
    "        else:\n",
    "\n",
    "            if i == 0:\n",
    "                audio_data[sub_path] = np.hstack([y[sub_path][i], y[sub_path][i+1]]) \n",
    "\n",
    "            elif i == 1:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                audio_data[sub_path] = np.hstack([audio_data[sub_path], y[sub_path][i]]) \n",
    "\n",
    "print(\"\\nStacked Audio raw data\")    \n",
    "for sub_path in range (0, nb_classes):        \n",
    "    print(audio_data[sub_path].shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked Audio raw data\n",
      "(22032544,)\n",
      "(23131808,)\n",
      "(10374368,)\n",
      "(13448160,)\n",
      "(16338976,)\n",
      "(24051424,)\n",
      "(23794944,)\n",
      "(15737600,)\n",
      "(18264160,)\n",
      "(13959936,)\n",
      "(12820608,)\n",
      "(25242336,)\n",
      "(28452384,)\n",
      "(25071328,)\n",
      "(12323840,)\n",
      "(27639552,)\n",
      "(16686944,)\n",
      "(21218464,)\n",
      "(11027616,)\n",
      "(19783072,)\n",
      "10374368\n",
      "1296796\n",
      "\n",
      "Resized Audio raw data\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n",
      "(1269600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStacked Audio raw data\")    \n",
    "for sub_path in range (0, nb_classes):        \n",
    "    print(audio_data[sub_path].shape)\n",
    "\n",
    "min = 9999999999\n",
    "\n",
    "for i in range (0, 5):\n",
    "    if min > audio_data[i].shape[0]:\n",
    "        min = audio_data[i].shape[0] \n",
    "\n",
    "print(min)\n",
    "\n",
    "input_data_size = 460\n",
    "\n",
    "min = int(min/8)\n",
    "\n",
    "print(min)\n",
    "\n",
    "\n",
    "min = min - min %(input_data_size * input_data_size)\n",
    "    \n",
    "\n",
    "print(\"\\nResized Audio raw data\")    \n",
    "for i in range (nb_classes):\n",
    "    audio_data[i] = audio_data[i][0:min]\n",
    "    print(audio_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (20, 2480)\n",
      "1 (20, 2480)\n",
      "2 (20, 2480)\n",
      "3 (20, 2480)\n",
      "4 (20, 2480)\n",
      "5 (20, 2480)\n",
      "6 (20, 2480)\n",
      "7 (20, 2480)\n",
      "8 (20, 2480)\n",
      "9 (20, 2480)\n",
      "10 (20, 2480)\n",
      "11 (20, 2480)\n",
      "12 (20, 2480)\n",
      "13 (20, 2480)\n",
      "14 (20, 2480)\n",
      "15 (20, 2480)\n",
      "16 (20, 2480)\n",
      "17 (20, 2480)\n",
      "18 (20, 2480)\n",
      "19 (20, 2480)\n"
     ]
    }
   ],
   "source": [
    "# mfcc\n",
    "\n",
    "mfcc = [None] * nb_classes\n",
    "\n",
    "for sub_class in range(nb_classes):\n",
    "    mfcc[sub_class] = librosa.feature.mfcc(y=audio_data[sub_class], sr=sr[0][0])\n",
    "    print(sub_class, mfcc[sub_class].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  2480\n",
      "0 (2480, 20)\n",
      "1 (2480, 20)\n",
      "2 (2480, 20)\n",
      "3 (2480, 20)\n",
      "4 (2480, 20)\n",
      "5 (2480, 20)\n",
      "6 (2480, 20)\n",
      "7 (2480, 20)\n",
      "8 (2480, 20)\n",
      "9 (2480, 20)\n",
      "10 (2480, 20)\n",
      "11 (2480, 20)\n",
      "12 (2480, 20)\n",
      "13 (2480, 20)\n",
      "14 (2480, 20)\n",
      "15 (2480, 20)\n",
      "16 (2480, 20)\n",
      "17 (2480, 20)\n",
      "18 (2480, 20)\n",
      "19 (2480, 20)\n",
      "0 (2480, 21)\n",
      "1 (2480, 21)\n",
      "2 (2480, 21)\n",
      "3 (2480, 21)\n",
      "4 (2480, 21)\n",
      "5 (2480, 21)\n",
      "6 (2480, 21)\n",
      "7 (2480, 21)\n",
      "8 (2480, 21)\n",
      "9 (2480, 21)\n",
      "10 (2480, 21)\n",
      "11 (2480, 21)\n",
      "12 (2480, 21)\n",
      "13 (2480, 21)\n",
      "14 (2480, 21)\n",
      "15 (2480, 21)\n",
      "16 (2480, 21)\n",
      "17 (2480, 21)\n",
      "18 (2480, 21)\n",
      "19 (2480, 21)\n"
     ]
    }
   ],
   "source": [
    "# labeling\n",
    "\n",
    "mfcc_size = mfcc[0].shape[1]\n",
    "print(\"mfcc_size: \", mfcc_size)\n",
    "\n",
    "\n",
    "for i in range (nb_classes):\n",
    "    mfcc[i] = mfcc[i].transpose()\n",
    "    print(i, mfcc[i].shape)\n",
    "\n",
    "\n",
    "for i in range (nb_classes):\n",
    "    y[i] = np.ones((mfcc_size, 1), dtype='int') * (i+1) -1\n",
    "\n",
    "    \n",
    "for i in range (nb_classes):\n",
    "    mfcc[i] = np.hstack([mfcc[i], y[i]])\n",
    "    print(i, mfcc[i].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49600, 21)\n",
      "[-355.47322428  132.43891591   43.9685361    27.86483132   29.9788611\n",
      "   21.52865928   13.18758545    1.44089212  -17.75298791  -14.89513085\n",
      "  -15.94091364  -11.43521358  -13.86867584  -14.51315314  -18.300715\n",
      "   -3.44977593    1.3422925     7.90889077   -0.86991238   -0.80604149\n",
      "    0.        ]\n",
      "(49600, 21)\n"
     ]
    }
   ],
   "source": [
    "# input data shuffling\n",
    "\n",
    "\n",
    "mfcc_append = []\n",
    "\n",
    "for i in range (0, nb_classes):\n",
    "    \n",
    "    if i == 0:\n",
    "        mfcc_append = np.vstack([mfcc[i], mfcc[i+1]])\n",
    "    \n",
    "    elif i == 1:\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        mfcc_append = np.vstack([mfcc_append, mfcc[i]])\n",
    "\n",
    "\n",
    "print(mfcc_append.shape)\n",
    "\n",
    "print(mfcc_append[20])\n",
    "\n",
    "\n",
    "np.random.shuffle(mfcc_append)\n",
    "\n",
    "mfcc_shuffle = mfcc_append\n",
    "print(mfcc_shuffle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL IN/OUTPUT SHAPE\n",
      "(49600, 20)\n",
      "(49600, 20)\n",
      "\n",
      "FINAL IN/OUTPUT DATA\n",
      "[[-370.10871822  112.98027944   29.61631237 ...   11.74968794\n",
      "     7.37475207    3.16256044]\n",
      " [-121.22956538  102.97050119  -32.89280822 ...   12.96843278\n",
      "    17.65834005   31.49661074]\n",
      " [-115.38645648  133.11006277  -53.07846612 ...    7.04108446\n",
      "    -6.61337952   -2.96491208]\n",
      " ...\n",
      " [-241.94323842   55.86097046   52.53813654 ...   -4.58395716\n",
      "   -16.3762113     4.28580356]\n",
      " [-186.90035391  117.78446615    7.2839688  ...   -2.87235367\n",
      "     0.89264194    4.8907196 ]\n",
      " [-207.48433864  101.00392039    5.83409878 ...   -2.56189437\n",
      "     5.83559383   -1.49801045]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# labeled value one-hot encoding\n",
    "\n",
    "mfcc_shuffle_T = mfcc_shuffle.transpose()\n",
    "\n",
    "x_data_t = mfcc_shuffle_T[:-1]\n",
    "y_data_t = mfcc_shuffle_T[-1:]\n",
    "x_data = x_data_t.transpose()\n",
    "y_data_t = y_data_t.flatten()\n",
    "\n",
    "\n",
    "\n",
    "y_data_one_hot = tf.one_hot(y_data_t, nb_classes, dtype=tf.float32)\n",
    "\n",
    "tf.InteractiveSession().as_default()\n",
    "tf.tables_initializer().run()\n",
    "\n",
    "y_data_one_hot = y_data_one_hot.eval()\n",
    "\n",
    "\n",
    "print(\"FINAL IN/OUTPUT SHAPE\")\n",
    "print(x_data.shape)\n",
    "print(y_data_one_hot.shape)\n",
    "\n",
    "print(\"\\nFINAL IN/OUTPUT DATA\")\n",
    "print(x_data)\n",
    "print(y_data_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN\n",
    "\n",
    "training_number = 18000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"sound_classifications-1-3\") as scope:\n",
    "    tf.variable_scope(scope, reuse=True)\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, 20])\n",
    "    Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", shape=[20, 500], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([500]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2\", shape=[500, 500], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([500]))\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "\n",
    "    W3 = tf.get_variable(\"W3\", shape=[500, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-77fb8f5bf4a3>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-17-77fb8f5bf4a3>:9: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "# Cross entropy cost/loss\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=hypothesis))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3907592\n",
      "10 0.6076664\n",
      "20 0.44021025\n",
      "30 0.3451095\n",
      "40 0.2798561\n",
      "50 0.24140732\n",
      "60 0.20487328\n",
      "70 0.15473998\n",
      "80 0.11410581\n",
      "Accuracy:  0.94590724\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "cost_history = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(int(training_number/batch_size)):\n",
    "        batch_count = int(x_data.shape[0]/batch_size)\n",
    "        \n",
    "        for i in range(batch_count):\n",
    "    \n",
    "            batch_xs, batch_ys = x_data[i* batch_size: i*batch_size+batch_size], y_data_one_hot[i*batch_size:i*batch_size+batch_size]\n",
    "        \n",
    "            sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "\n",
    "            curr_cost = sess.run(cost, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            \n",
    "            \n",
    "        if epoch % 10 == 0:    \n",
    "            print(epoch, curr_cost)\n",
    "            cost_history.append(curr_cost)\n",
    "                                \n",
    "                                \n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: x_data, Y: y_data_one_hot})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
